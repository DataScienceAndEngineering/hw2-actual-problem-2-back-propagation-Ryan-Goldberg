{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW2: Problem 2: Calculate Backpropagation from Michael Nielsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. BP3: $\\frac{\\partial C}{\\partial b^L_j} = \\delta ^L_j$\n",
    "\n",
    "Proof:\n",
    "\n",
    "Given:\n",
    "C = $\\frac{1}{2}||y-a^L||^2 $ = $\\frac{1}{2} \\Sigma_j(y_j - a^L_j)^2$\n",
    "\n",
    "Definition:\n",
    "$$\n",
    "\\delta^L_j = \\frac{\\partial C}{\\partial z^L_j}\n",
    "$$\n",
    "Chain Rule:\n",
    "$$\n",
    "\\delta^L_j = \\Sigma_k \\frac{\\partial C}{\\partial b^L_k} \\frac{\\partial b^L_k}{\\partial z^l_j}\n",
    "$$\n",
    "Second term on right is zero if k $\\neq$ j because Z only depends on biases in its own layer simplifying to:\n",
    "$$\n",
    "\\delta^L_j = \\frac{\\partial C}{\\partial b^L_j} \\frac{\\partial b^L_j}{\\partial z^l_j}\n",
    "$$\n",
    "Now since:\n",
    "$$\n",
    "z^L_j = \\Sigma_k w^L_{jk}a^{L-1}_k + b^L_j  \\rightarrow \\frac{\\partial b^L_j}{\\partial z^L_j} = 1\n",
    "$$\n",
    "We can further simplify to get BP3:\n",
    "$$\n",
    "\\delta^L_j = \\frac{\\partial C}{\\partial b^L_j}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. BP4: $\\frac{\\partial C}{\\partial w^L_{jk}} = a^{L-1}_k \\delta^L_j $\n",
    "\n",
    "Proof:\n",
    "\n",
    "Definition:\n",
    "$$\n",
    "\\delta^L_j = \\frac{\\partial C}{\\partial z^L_j}\n",
    "$$\n",
    "Chain Rule:\n",
    "$$\n",
    "\\delta^L_j = \\Sigma_k \\frac{\\partial C}{\\partial w^L_{jk}} \\frac{\\partial w^L_{jk}}{\\partial z^l_j}\n",
    "$$\n",
    "\n",
    "Since:\n",
    "$$\n",
    "z^L_j = \\Sigma_k w^L_{jk}a^{L-1}_k + b^L_j \\rightarrow \\frac{\\partial w^L_{jk}}{\\partial z^L_j} = \\frac{1}{\\Sigma_k a^{L-1}_k}\n",
    "$$\n",
    "\n",
    "We can rearrange to get:\n",
    "$$\n",
    "\\delta^L_j = \\Sigma_k \\frac{\\partial C}{\\partial w^L_{jk}} \\frac{1}{\\partial a^{L-1}_k}\n",
    "$$\n",
    "Rearrangeing once more we get BP4:\n",
    "$$\n",
    "\\Sigma_k a^{L-1}_k \\delta^L_j = \\Sigma_k \\frac{\\partial C}{\\partial w^L_{jk}} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Backprop in matrix form\n",
    "\n",
    "Have matrix of weights and biases for entire network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(self, x, y):\n",
    "    \"\"\"Return a tuple \"(nabla_b, nabla_w)\" representing the\n",
    "    gradient for the cost function C_x.  \"nabla_b\" and\n",
    "    \"nabla_w\" are layer-by-layer lists of numpy arrays, similar\n",
    "    to \"self.biases\" and \"self.weights\".\"\"\"\n",
    "    nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(self.biases, self.weights):\n",
    "        z = np.dot(w, activation)+b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "    # backward pass\n",
    "    delta = self.cost_derivative(activations[-1], y) * \\\n",
    "        sigmoid_prime(zs[-1])\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "    # Note that the variable l in the loop below is used a little\n",
    "    # differently to the notation in Chapter 2 of the book.  Here,\n",
    "    # l = 1 means the last layer of neurons, l = 2 is the\n",
    "    # second-last layer, and so on.  It's a renumbering of the\n",
    "    # scheme in the book, used here to take advantage of the fact\n",
    "    # that Python can use negative indices in lists.\n",
    "    for l in xrange(2, self.num_layers):\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "    return (nabla_b, nabla_w)\n",
    "\n",
    "def backdrop_matrix(self, x, y)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
